@article{mitchell1997machine,
    title={Machine learning. 1997},
    author={Mitchell, Tom M and others},
    journal={Burr Ridge, IL: McGraw Hill},
    volume={45},
    number={37},
    pages={870--877},
    year={1997}
}
@book{russell2016artificial,
    title={Artificial intelligence: a modern approach},
    author={Russell, Stuart J and Norvig, Peter},
    year={2016},
    publisher={Malaysia; Pearson Education Limited,}
}
@article{heinrich2016deep,
    title={Deep reinforcement learning from self-play in imperfect-information games},
    author={Heinrich, Johannes and Silver, David},
    journal={arXiv preprint arXiv:1603.01121},
    year={2016}
}
@inproceedings{sutton2000policy,
    title={Policy gradient methods for reinforcement learning with function approximation},
    author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
    booktitle={Advances in neural information processing systems},
    pages={1057--1063},
    year={2000}
}
@article{kaelbling1996reinforcement,
    title={Reinforcement learning: A survey},
    author={Kaelbling, Leslie Pack and Littman, Michael L and Moore, Andrew W},
    journal={Journal of artificial intelligence research},
    volume={4},
    pages={237--285},
    year={1996}
}
@inproceedings{shi2000abstraction,
    title={Abstraction methods for game theoretic poker},
    author={Shi, Jiefu and Littman, Michael L},
    booktitle={International Conference on Computers and Games},
    pages={333--345},
    year={2000},
    organization={Springer}
}
@article{dahl2002lagging,
    title={The lagging anchor algorithm: Reinforcement learning in two-player zero-sum games with imperfect information},
    author={Dahl, Fredrik A},
    journal={Machine Learning},
    volume={49},
    number={1},
    pages={5--37},
    year={2002},
    publisher={Springer}
}
@inproceedings{dahl2001reinforcement,
    title={A reinforcement learning algorithm applied to simplified two-player Texas Holdâ€™em poker},
    author={Dahl, Fredrik A},
    booktitle={European Conference on Machine Learning},
    pages={85--96},
    year={2001},
    organization={Springer}
}
@article{moravvcik2017deepstack,
    title={Deepstack: Expert-level artificial intelligence in heads-up no-limit poker},
    author={Morav{\v{c}}{\'\i}k, Matej and Schmid, Martin and Burch, Neil and Lis{\`y}, Viliam and Morrill, Dustin and Bard, Nolan and Davis, Trevor and Waugh, Kevin and Johanson, Michael and Bowling, Michael},
    journal={Science},
    volume={356},
    number={6337},
    pages={508--513},
    year={2017},
    publisher={American Association for the Advancement of Science}
}
@incollection{littman1994markov,
    title={Markov games as a framework for multi-agent reinforcement learning},
    author={Littman, Michael L},
    booktitle={Machine Learning Proceedings 1994},
    pages={157--163},
    year={1994},
    publisher={Elsevier}
}
@article{furnkranz2001machine,
    title={Machine learning in games: A survey},
    author={F{\"u}rnkranz, Johannes},
    journal={Machines that learn to play games},
    pages={11--59},
    year={2001},
    publisher={Huntington, NY: Nova Science Publishers}
}
@book{sutton1998reinforcement,
    title={Reinforcement learning: An introduction},
    author={Sutton, Richard S and Barto, Andrew G and Bach, Francis and others},
    year={1998},
    publisher={MIT press}
}
@phdthesis{watkins1989learning,
    title={Learning from delayed rewards},
    author={Watkins, Christopher John Cornish Hellaby},
    year={1989},
    school={King's College, Cambridge}
}
@inproceedings{vermorel2005multi,
    title={Multi-armed bandit algorithms and empirical evaluation},
    author={Vermorel, Joannes and Mohri, Mehryar},
    booktitle={European conference on machine learning},
    pages={437--448},
    year={2005},
    organization={Springer}
}