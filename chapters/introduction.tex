\chapter{Introduction (10)}
\label{ch:intro}

\section{Overview (3)}\label{sec:overview}
Since the inception of machine learning, games have been a key problem area that has seen a lot of focus from
top academics.
For decades games have been used as a platform to test and develop algorithms that have go on to provide invaluable
services that are used peoples's everyday life.
The ability to contribute to this great history was a large motivator when it came to choosing this project.

Although this report will, to an extent, discuss machine learning and how it applies to games in general, the
primary focus will be on machine learning techniques when applied to texas hold'em, or variations of it.
In the past, methods such as Counterfactual Regret Minimization (CFR) have been used to develop agents that can
play texas hold'em to a superhuman level.
CFR is an algorithm that allows computation of a strategy through self-play.
The metric used to update these strategies is called regret, which measures the difference between the
game's outcome and the outcome that could have been achieved if some other action was taken.
A large number of simulated games are played, with regret being calculated each time in order to compute a
strategy that is optimal.
One example of CFR being used was the 2018 annual computer poker competition champion, slumbot\citep{jackson2013slumbot}.

There have also been attempts to tackle texas hold'em using a machine learning paradigm called reinforcement learning (RL).
Reinforcement learning is a way of programming agents by reward and punishment without needing to specify how the
task is to be achieved\citep{kaelbling1996reinforcement}.
In one case RL was combined with techniques inspired by game theory\citep{heinrich2016deep}.
In another linear programming techniques and RL were used in order to tackle a
simplified version of the game\citep{dahl2001reinforcement}.

These different approaches will be discussed in greater detail in the background section.

\section{Objectives (2)}\label{sec:objectives}
\subsection{Primary Objectives}\label{subsec:primaryObjectives}

Although this project will be largely research based, the primary goal is to create a texas hold'em
playing agent.
Due to the fact that texas hold'em has an extremely large state space, combined with the fact that it
is an imperfect information game, the initial goal will be to tackle a simplified version of the game.
Specifically Leduc Hold'em will be used for this version of the project.
This version of hold'em consists of a six card deck and only one private card, compared to two in texas hold'em.

If the success criteria for this simplified version of the game are met, we will then proceed to tackle
a more complex version of the game.
In this second iteration of the project we will tackle limit texas hold'em with the goal of recreating
the results shown by Heinrich.

It is also my goal to create a product that will be fun and useful for the general public.
As such another objective will be to create a website that will allow users to play heads-up against the final product.

\subsection{Secondary Objectives}\label{subsec:secondaryObjectives}
As this project is very specific and academic, one of the larger challenges will be to gain a strong knowledge
of the domain.
This means learning the history of RL, the types of problems that it has been used to solve and the specific details of
different RL algorithms.

The same can be said

A successful project will require a high degree of knowledge from the broader domain of RL. However, it is also the case
that I must become closely familiar with the existing academic literature in the area of RL with respect to imperfect
information games.
This will allow me to avoid taking approaches that have previously shown to fail as well as allow me to add value to
the existing literature whether that be through literature review or through my own experimental findings.


\section{Contribution (1)}\label{sec:contribution}

\section{Methodology}\label{sec:methodology}

\section{Motivation (2)}\label{sec:Motivation}